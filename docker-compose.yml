version: "3.8"

services:
  airflow:
    image: apache/airflow:2.9.2
    container_name: airflow
    env_file:
      - ./.env
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE=America/Sao_Paulo
      - AIRFLOW__CORE__FERNET_KEY=${FERNET_KEY}
      # Conecta no PostgreSQL 9.3 LOCAL (fora do Docker)
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_DB_USER}:${AIRFLOW_DB_PASSWORD}@host.docker.internal:5432/${AIRFLOW_DB_NAME}
      - PIP_ADDITIONAL_REQUIREMENTS=dbt-core==1.7.14 dbt-postgres==1.7.14 psycopg2-binary==2.9.9 requests==2.32.3 PyYAML==6.0.2 pandas==2.2.2
      - DBT_PROFILES_DIR=/opt/dbt/profiles
      - PYTHONPATH=/opt
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./inep:/opt/inep
      - ./dbt:/opt/dbt
      - ./.env:/opt/airflow/.env:ro
    entrypoint: >
      bash -c "
      echo 'Aguardando PostgreSQL 9.3 no host...';
      while ! pg_isready -h host.docker.internal -p 5432; do sleep 2; done;
      echo 'Inicializando banco de metadados do Airflow...';
      airflow db upgrade &&
      airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true &&
      echo 'Iniciando scheduler e webserver...';
      airflow scheduler & exec airflow webserver
      "
    networks:
      - airflow-net

  dbt-cli:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.14
    container_name: dbt-cli
    env_file:
      - ./.env
    environment:
      - DBT_PROFILES_DIR=/opt/dbt/profiles
      # Para o dbt tamb√©m mirar no seu Postgres 9.3
      - POSTGRES_HOST=host.docker.internal
    volumes:
      - ./dbt:/opt/dbt
      - ./.env:/opt/dbt/.env:ro
    networks:
      - airflow-net

networks:
  airflow-net:
